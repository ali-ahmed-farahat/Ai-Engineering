{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing all necessary tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) let's read the data from csv file and select the predictors and the target from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"concrete_data.csv\")\n",
    "data_columns = data.columns\n",
    "predictors = data[data_columns[data_columns != \"Strength\"]]\n",
    "target = data['Strength']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) identify the num of columns of the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) split the data for training and testing and with 30% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=30/100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) create neural network by adding only one layer with 10 nodes which has input shaped as the num of columns from the predictors and uses adam  optimizer and loss function of mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_basic_NN(num_cols):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Dense(10, activation = 'relu', input_shape=(num_cols,)))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) initializing the mean_squared_errors list to save future values of mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_errors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) creating for loop to iterate 50 times, to create and fit and calculate the mse for the model then appending it to the mean_squared_errors list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(50):\n",
    "    my_model = build_basic_NN(num_cols)\n",
    "    my_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = 50, verbose = 0)\n",
    "    prediction = my_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, prediction)\n",
    "    mean_squared_errors.append(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) calculating the mean and the standard deviation for the mse for the whole list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_of_mse = np.mean(mean_squared_errors)\n",
    "std_dev_mse = np.std(mean_squared_errors)\n",
    "\n",
    "print('mean of MSEs is -> ', mean_of_mse)\n",
    "print(\"standard devation of MSEs is -> \", std_dev_mse)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
